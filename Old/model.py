# # Initializing Spark
# import findspark
# findspark.init()

# # Importing PySpark related
# from pyspark import SparkContext
# from pyspark.sql import SparkSession
# import collections

# Importing TensorFlow
import tensorflow as tf
# import tensorflowonspark as tfos
# from tensorflowonspark import TFCluster # Needs package 'packaging' to be installed manually to run properly

from tensorflow.keras import layers, models
import tensorflow.keras as keras

# Importing other packages
import librosa
import librosa.display
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from tqdm import tqdm
from IPython import display
import os

# Hiding pysoundfile warning generated by librosa
import warnings
warnings.filterwarnings("ignore", message="pysoundfile")

# text = pd.read_csv('./data/cv-valid-train.csv')
text = pd.read_pickle('testingSentence')
textOnly = pd.DataFrame(text.reindex(text.text.str.len().sort_values().index)).reset_index().drop(['index'], axis=1)


def getBands(data):
    return np.array([np.abs([j[0] for j in librosa.stft(data[i*320:(i+1)*320], hop_length = 321)]) for i in range(int(len(data)/320))])

# Function to pad audio arrays to equal length for neural net
def padAudio(track, desired):
    
    padding = desired - track.shape[0]
    filler = np.array([0.0 for i in range(len(track[0]))])
#     .reshape(-1, 1)
    appendix = np.array([filler for i in range(padding)])
    
    try:
        return np.concatenate((track, appendix), axis = 0)
    except:
        print(track.shape)

# Function to load audio data
def loadAudio(filename):
    data, _ = librosa.load(f'./data/cv-valid-train/{filename}', sr=16000)
    bands = getBands(data)
    padded = padAudio(bands, 2000)
    return padded.reshape(1, 2000, 1025)


def prepareDataForModel(frame, numberOfElements=0):
    X = []
    y = []

    if numberOfElements == 0:
        numberOfElements = frame.shape[0]

    for i in tqdm(frame.head(numberOfElements).iterrows(), total=frame.head(numberOfElements).shape[0], desc='Preprocessing Audio'):
        X.append(loadAudio(i[1]['filename']))
    
    y = list(textOnly.head(numberOfElements)['text'])
    for index, txt in enumerate(y):
        y[index] = list(txt.upper().replace(' ', '_'))
        while len(y[index]) < 200:
            y[index].append(' ')
        # Encode in ASCII
        y[index] = [ord(i) for i in y[index]]
    
    X = np.array(X)
    y = np.array(y)

    return X, y

# Defining and structuring model
model = models.Sequential()
model.add(layers.Input(shape=(1, 2000, 1025)))
model.add(layers.Conv2D(32, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))
model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))
model.add(layers.Conv2D(64, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))
model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))
model.add(layers.Conv2D(128, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))
model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))
model.add(layers.Conv2D(256, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))
model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))
model.add(layers.Reshape((2000,256)))
model.add(layers.LSTM(256, activation='tanh', dropout=0.2, recurrent_dropout=0.2))
model.add(layers.Dense(200, activation='softmax'))

# Compiling model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

model.summary()



if os.path.exists('X.npy'):
    X = np.load('X.npy')
    y = np.load('y.npy')
else:
    X, y = prepareDataForModel(textOnly)
    np.save('X', X)
    np.save('y', y)


model.fit(X, y, epochs=1, batch_size=1)

# from tensorflow.python.client import device_lib
# print(device_lib.list_local_devices())