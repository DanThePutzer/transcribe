{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Importing PySpark related\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TensorFlow\n",
    "import tensorflow as tf\n",
    "import tensorflowonspark as tfos\n",
    "from tensorflowonspark import TFCluster # Needs package 'packaging' to be installed manually to run properly\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other packages\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython import display\n",
    "\n",
    "# Hiding pysoundfile warning generated by librosa\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"pysoundfile\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loading of audio data\n",
    "data, sampleRate = librosa.load('./data/cv-valid-train/cv-valid-train/sample-000001.mp3', sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(data, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('./data/cv-valid-train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "textOnly = pd.DataFrame(text.reindex(text.text.str.len().sort_values().index)).reset_index().drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstTest = textOnly.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load audio data\n",
    "def loadAudio(filename):\n",
    "    data, _ = librosa.load(f'./data/cv-valid-train/{filename}', sr=16000)\n",
    "    bands = getBands(data)\n",
    "    padded = padAudio(bands, 1000)\n",
    "    return padded.reshape(1, 1000, 1025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77177eeac2e457dbf3f927dbf35a3fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "for i in tqdm(firstTest.iterrows(), total=firstTest.shape[0]):\n",
    "    X.append(loadAudio(i[1]['filename']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "textAsList = list(firstTest['text'])\n",
    "for index, txt in enumerate(textAsList):\n",
    "    textAsList[index] = list(txt.upper().replace(' ', '_'))\n",
    "    while len(textAsList[index]) < 200:\n",
    "        textAsList[index].append(' ')\n",
    "    # Encode in ASCII\n",
    "    textAsList[index] = [ord(i) for i in textAsList[index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(textAsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65, 77, 69, ..., 32, 32, 32],\n",
       "       [65, 77, 69, ..., 32, 32, 32],\n",
       "       [65, 77, 69, ..., 32, 32, 32],\n",
       "       ...,\n",
       "       [77, 65, 89, ..., 32, 32, 32],\n",
       "       [84, 82, 89, ..., 32, 32, 32],\n",
       "       [65, 78, 68, ..., 32, 32, 32]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting audio wave\n",
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveplot(data, sr = sampleRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = data[0:320]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs([i[0] for i in librosa.stft(data[:320], hop_length = 321)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBands(data):\n",
    "    return np.array([np.abs([j[0] for j in librosa.stft(data[i*320:(i+1)*320], hop_length = 321)]) for i in range(int(len(data)/320))])\n",
    "#     for i in range(int(len(data)/320)):\n",
    "#         test = data[i*320:(i+1)*320]\n",
    "#         samples.append(np.abs(librosa.stft(test, hop_length = 321)))\n",
    "        \n",
    "#     return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = getBands(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "librosa.display.specshow(bands[0], y_axis = 'log', cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad audio arrays to equal length for neural net\n",
    "def padAudio(track, desired):\n",
    "#     print(track.shape)\n",
    "    \n",
    "    padding = desired - track.shape[0]\n",
    "    filler = np.array([0.0 for i in range(len(track[0]))])\n",
    "#     .reshape(-1, 1)\n",
    "    appendix = np.array([filler for i in range(padding)])\n",
    "#     print(appendix.shape)\n",
    "    \n",
    "    return np.concatenate((track, appendix), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(160000 - data.shape[0]):\n",
    "    data = np.concatenate((data, [0.0]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Audio(data, rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lel = padAudio(bands, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lel.reshape(1, 1000, 1025).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped = np.array(list(lel.reshape(-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 4))\n",
    "# librosa.display.waveplot(reshaped, sr = sampleRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display.Audio(reshaped, rate = 44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = 0\n",
    "for i in tqdm(range(1000)):\n",
    "    loopData, _ = librosa.load(f'./data/cv-valid-train/cv-valid-train/sample-{\"{:06d}\".format(i)}.mp3', res_type = 'kaiser_fast', sr=16000)\n",
    "    length = getBands(loopData).shape[0]\n",
    "    if (length > maxLen):\n",
    "        maxLen = length\n",
    "        \n",
    "print(maxLen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{:06d}\".format(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Input(shape=(1, 1000, 1025)))\n",
    "model.add(layers.Conv2D(32, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))\n",
    "model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))\n",
    "model.add(layers.Conv2D(64, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))\n",
    "model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))\n",
    "model.add(layers.Conv2D(128, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))\n",
    "model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))\n",
    "model.add(layers.Conv2D(256, kernel_size=[5,5], padding='same', activation='relu', data_format='channels_first'))\n",
    "model.add(layers.MaxPooling2D(pool_size=[1,5], data_format='channels_first'))\n",
    "model.add(layers.Reshape((1000,256)))\n",
    "model.add(layers.LSTM(256, activation='tanh', dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(200, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 1000, 1025)    832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 32, 1000, 205)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 1000, 205)     51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 1000, 41)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 128, 1000, 41)     204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 1000, 8)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 1000, 8)      819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 256, 1000, 1)      0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1000, 256)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               51400     \n",
      "=================================================================\n",
      "Total params: 1,653,192\n",
      "Trainable params: 1,653,192\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples\n"
     ]
    }
   ],
   "source": [
    "model.fit(X, y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
