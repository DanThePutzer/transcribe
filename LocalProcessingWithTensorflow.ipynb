{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing other packages\n",
    "import numpy as np\n",
    "import librosa\n",
    "import io\n",
    "import os\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processSample(path, sample): \n",
    "    # Reading audio files\n",
    "    audio = sf.read(os.path.join(path, sample))[0]\n",
    "\n",
    "    # Padding audio to 1 second if slightly shorter\n",
    "    if len(audio) < 16000:\n",
    "        audio = np.concatenate((audio, np.zeros(16000 - len(audio),)), axis=0)\n",
    "    # Cutting audio to 1 second if slightly longer\n",
    "    elif len(audio) > 16000:\n",
    "        audio = audio[:16000]\n",
    "\n",
    "    # Applying Fourier transformation\n",
    "    return librosa.amplitude_to_db(abs(librosa.stft(audio, hop_length=321)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to train data\n",
    "mainPath = 'data/train/audio/'\n",
    "\n",
    "numpyAudio = []\n",
    "labels = []\n",
    "\n",
    "# Looping over directory\n",
    "for word in os.listdir(mainPath):\n",
    "    specPath = os.path.join(mainPath, word)\n",
    "    \n",
    "    # Looping over samples\n",
    "    for sample in tqdm(os.listdir(specPath), desc=f\"Processing Word: {word}\"):\n",
    "        # Applying processing function\n",
    "        transformed = processSample(specPath, sample)\n",
    "        numpyAudio.append(transformed)\n",
    "        labels.append(word)\n",
    "\n",
    "try:\n",
    "    numpyAudio = np.array(numpyAudio)\n",
    "    _, labels = np.unique(labels, return_inverse=True)\n",
    "    \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Data Model-Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating numpy arrays\n",
    "# Skipping last 5 samples because they are not part of what we want to train on\n",
    "X = np.array(numpyAudio[:-5])\n",
    "y = np.array(labels[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving processed data\n",
    "np.save('X', X)\n",
    "np.save('y', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping X for model\n",
    "X = X.reshape(-1, 1025, 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding y values\n",
    "_, y = np.unique(y, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling X and y in unison\n",
    "from sklearn.utils import shuffle\n",
    "X_Shuffled, y_Shuffled = shuffle(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving shuffled data\n",
    "np.save('X_Shuffled', X_Shuffled)\n",
    "np.save('y_Shuffled', y_Shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute when already processed and saved data before\n",
    "# Loading Regular Data\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only execute when already processed and saved data before\n",
    "# Loading Shuffled Data\n",
    "X_Shuffled = np.load('X_Shuffled.npy')\n",
    "y_Shuffled = np.load('y_Shuffled.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Importing classes necessary for neural net\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Flatten, Conv2D, MaxPool2D, Input, BatchNormalization\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating model\n",
    "model = Sequential()\n",
    "\n",
    "# Building model structure\n",
    "model.add(Input(shape=(1025, 50, 1)))\n",
    "\n",
    "# First convolution and pooling step\n",
    "model.add(Conv2D(16, kernel_size=[3,3], activation='relu', data_format='channels_last'))\n",
    "model.add(MaxPool2D(pool_size=[3,3], data_format='channels_last'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Second convolution and pooling step\n",
    "model.add(Conv2D(32, kernel_size=[3,3], activation='relu', data_format='channels_last'))\n",
    "model.add(MaxPool2D(pool_size=[3,3], data_format='channels_last'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Flattening convolutional output for Dense layers\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layers\n",
    "model.add(Dense(30, activation='softmax'))\n",
    "\n",
    "# Compiling model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing If GPU In Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up Tensorboard\n",
    "import datetime\n",
    "\n",
    "logDir = os.path.join(\"Logs\", 'Model-' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tbCallback = tf.keras.callbacks.TensorBoard(log_dir=logDir, histogram_freq=1, profile_batch=10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_Shuffled, y_Shuffled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=5, callbacks=[tbCallback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
